{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hooke and Jeeves Pattern Search \n",
    "\n",
    "describe the method in words\n",
    "\n",
    "then example code below from [https://searchcode.com/file/66639051/hooke_jeeves_bounded.py/](https://searchcode.com/file/66639051/hooke_jeeves_bounded.py/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#     This is a direct python port of Mark G. Johnson's C implementation of the Hooke and Jeeves algorithm\n",
    "#     \n",
    "#     Sean R. Johnson, July 7, 2013\n",
    "#     \n",
    "#     immediately below is the original documentation\n",
    "#     in the body, comments marked with ## are from the original,\n",
    "#     other comments are my own\n",
    "#\n",
    "\n",
    "#/* Nonlinear Optimization using the algorithm of Hooke and Jeeves  */\n",
    "#/*\t12 February 1994\tauthor: Mark G. Johnson \t   */\n",
    "\n",
    "#/* Find a point X where the nonlinear function f(X) has a local    */\n",
    "#/* minimum.  X is an n-vector and f(X) is a scalar.  In mathe-\t   */\n",
    "#/* matical notation  f: R^n -> R^1.  The objective function f()    */\n",
    "#/* is not required to be continuous.  Nor does f() need to be\t   */\n",
    "#/* differentiable.  The program does not use or require \t   */\n",
    "#/* derivatives of f().\t\t\t\t\t\t   */\n",
    "\n",
    "#/* The software user supplies three things: a subroutine that\t   */\n",
    "#/* computes f(X), an initial \"starting guess\" of the minimum point */\n",
    "#/* X, and values for the algorithm convergence parameters.  Then   */\n",
    "#/* the program searches for a local minimum, beginning from the    */\n",
    "#/* starting guess, using the Direct Search algorithm of Hooke and  */\n",
    "#/* Jeeves.\t\t\t\t\t\t\t   */\n",
    "\n",
    "#/* This C program is adapted from the Algol pseudocode found in    */\n",
    "#/* \"Algorithm 178: Direct Search\" by Arthur F. Kaupe Jr., Commun-  */\n",
    "#/* ications of the ACM, Vol 6. p.313 (June 1963).  It includes the */\n",
    "#/* improvements suggested by Bell and Pike (CACM v.9, p. 684, Sept */\n",
    "#/* 1966) and those of Tomlin and Smith, \"Remark on Algorithm 178\"  */\n",
    "#/* (CACM v.12).  The original paper, which I don't recommend as    */\n",
    "#/* highly as the one by A. Kaupe, is:  R. Hooke and T. A. Jeeves,  */\n",
    "#/* \"Direct Search Solution of Numerical and Statistical Problems\", */\n",
    "#/* Journal of the ACM, Vol. 8, April 1961, pp. 212-229. \t   */\n",
    "\n",
    "#/* Calling sequence:\t\t\t\t\t\t   */\n",
    "#/*  int hooke(nvars, startpt, endpt, rho, epsilon, itermax)\t   */\n",
    "#/*\t\t\t\t\t\t\t\t   */\n",
    "#/*     nvars\t   {an integer}  This is the number of dimensions  */\n",
    "#/*\t\t   in the domain of f().  It is the number of\t   */\n",
    "#/*\t\t   coordinates of the starting point (and the\t   */\n",
    "#/*\t\t   minimum point.)\t\t\t\t   */\n",
    "#/*     startpt\t   {an array of doubles}  This is the user-\t   */\n",
    "#/*\t\t   supplied guess at the minimum.\t\t   */\n",
    "#/*     endpt\t   {an array of doubles}  This is the location of  */\n",
    "#/*\t\t   the local minimum, calculated by the program    */\n",
    "#/*     rho\t   {a double}  This is a user-supplied convergence */\n",
    "#/*\t\t   parameter (more detail below), which should be  */\n",
    "#/*\t\t   set to a value between 0.0 and 1.0.\tLarger\t   */\n",
    "#/*\t\t   values of rho give greater probability of\t   */\n",
    "#/*\t\t   convergence on highly nonlinear functions, at a */\n",
    "#/*\t\t   cost of more function evaluations.  Smaller\t   */\n",
    "#/*\t\t   values of rho reduces the number of evaluations */\n",
    "#/*\t\t   (and the program running time), but increases   */\n",
    "#/*\t\t   the risk of nonconvergence.\tSee below.\t   */\n",
    "#/*     epsilon\t   {a double}  This is the criterion for halting   */\n",
    "#/*\t\t   the search for a minimum.  When the algorithm   */\n",
    "#/*\t\t   begins to make less and less progress on each   */\n",
    "#/*\t\t   iteration, it checks the halting criterion: if  */\n",
    "#/*\t\t   the stepsize is below epsilon, terminate the    */\n",
    "#/*\t\t   iteration and return the current best estimate  */\n",
    "#/*\t\t   of the minimum.  Larger values of epsilon (such */\n",
    "#/*\t\t   as 1.0e-4) give quicker running time, but a\t   */\n",
    "#/*\t\t   less accurate estimate of the minimum.  Smaller */\n",
    "#/*\t\t   values of epsilon (such as 1.0e-7) give longer  */\n",
    "#/*\t\t   running time, but a more accurate estimate of   */\n",
    "#/*\t\t   the minimum. \t\t\t\t   */\n",
    "#/*     itermax\t   {an integer}  A second, rarely used, halting    */\n",
    "#/*\t\t   criterion.  If the algorithm uses >= itermax    */\n",
    "#/*\t\t   iterations, halt.\t\t\t\t   */\n",
    "\n",
    "\n",
    "#/* The user-supplied objective function f(x,n) should return a C   */\n",
    "#/* \"double\".  Its  arguments are  x -- an array of doubles, and    */\n",
    "#/* n -- an integer.  x is the point at which f(x) should be\t   */\n",
    "#/* evaluated, and n is the number of coordinates of x.\tThat is,   */\n",
    "#/* n is the number of coefficients being fitted.\t\t   */\n",
    "\n",
    "#/* rho, the algorithm convergence control\t\t\t   */\n",
    "#/*\tThe algorithm works by taking \"steps\" from one estimate of */\n",
    "#/*    a minimum, to another (hopefully better) estimate.  Taking   */\n",
    "#/*    big steps gets to the minimum more quickly, at the risk of   */\n",
    "#/*    \"stepping right over\" an excellent point.  The stepsize is   */\n",
    "#/*    controlled by a user supplied parameter called rho.  At each */\n",
    "#/*    iteration, the stepsize is multiplied by rho  (0 < rho < 1), */\n",
    "#/*    so the stepsize is successively reduced.\t\t\t   */\n",
    "#/*\tSmall values of rho correspond to big stepsize changes,    */\n",
    "#/*    which make the algorithm run more quickly.  However, there   */\n",
    "#/*    is a chance (especially with highly nonlinear functions)\t   */\n",
    "#/*    that these big changes will accidentally overlook a\t   */\n",
    "#/*    promising search vector, leading to nonconvergence.\t   */\n",
    "#/*\tLarge values of rho correspond to small stepsize changes,  */\n",
    "#/*    which force the algorithm to carefully examine nearby points */\n",
    "#/*    instead of optimistically forging ahead.\tThis improves the  */\n",
    "#/*    probability of convergence.\t\t\t\t   */\n",
    "#/*\tThe stepsize is reduced until it is equal to (or smaller   */\n",
    "#/*    than) epsilon.  So the number of iterations performed by\t   */\n",
    "#/*    Hooke-Jeeves is determined by rho and epsilon:\t\t   */\n",
    "#/*\t    rho**(number_of_iterations) = epsilon\t\t   */\n",
    "#/*\tIn general it is a good idea to set rho to an aggressively */\n",
    "#/*    small value like 0.5 (hoping for fast convergence).  Then,   */\n",
    "#/*    if the user suspects that the reported minimum is incorrect  */\n",
    "#/*    (or perhaps not accurate enough), the program can be run\t   */\n",
    "#/*    again with a larger value of rho such as 0.85, using the\t   */\n",
    "#/*    result of the first minimization as the starting guess to    */\n",
    "#/*    begin the second minimization.\t\t\t\t   */\n",
    "\n",
    "#/* Normal use: (1) Code your function f() in the C language\t   */\n",
    "#/*\t       (2) Install your starting guess {or read it in}\t   */\n",
    "#/*\t       (3) Run the program\t\t\t\t   */\n",
    "#/*\t       (4) {for the skeptical}: Use the computed minimum   */\n",
    "#/*\t\t      as the starting point for another run\t   */\n",
    "\n",
    "#/* Data Fitting:\t\t\t\t\t\t   */\n",
    "#/*\tCode your function f() to be the sum of the squares of the */\n",
    "#/*\terrors (differences) between the computed values and the   */\n",
    "#/*\tmeasured values.  Then minimize f() using Hooke-Jeeves.    */\n",
    "#/*\tEXAMPLE: you have 20 datapoints (ti, yi) and you want to   */\n",
    "#/*\tfind A,B,C such that  (A*t*t) + (B*exp(t)) + (C*tan(t))    */\n",
    "#/*\tfits the data as closely as possible.  Then f() is just    */\n",
    "#/*\tf(x) = SUM (measured_y[i] - ((A*t[i]*t[i]) + (B*exp(t[i])) */\n",
    "#/*\t\t\t\t  + (C*tan(t[i]))))^2\t\t   */\n",
    "#/*\twhere x[] is a 3-vector consisting of {A, B, C}.\t   */\n",
    "\n",
    "#/*\t\t\t\t\t\t\t\t   */\n",
    "#/*  The author of this software is M.G. Johnson.\t\t   */\n",
    "#/*  Permission to use, copy, modify, and distribute this software  */\n",
    "#/*  for any purpose without fee is hereby granted, provided that   */\n",
    "#/*  this entire notice is included in all copies of any software   */\n",
    "#/*  which is or includes a copy or modification of this software   */\n",
    "#/*  and in all copies of the supporting documentation for such\t   */\n",
    "#/*  software.  THIS SOFTWARE IS BEING PROVIDED \"AS IS\", WITHOUT    */\n",
    "#/*  ANY EXPRESS OR IMPLIED WARRANTY.  IN PARTICULAR, NEITHER THE   */\n",
    "#/*  AUTHOR NOR AT&T MAKE ANY REPRESENTATION OR WARRANTY OF ANY\t   */\n",
    "#/*  KIND CONCERNING THE MERCHANTABILITY OF THIS SOFTWARE OR ITS    */\n",
    "#/*  FITNESS FOR ANY PARTICULAR PURPOSE. \t\t\t   */\n",
    "#/*\t\t\t\t\t\t\t\t   */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    '''\n",
    "        ## Rosenbrocks classic parabolic valley (\"banana\") function\n",
    "    '''\n",
    "    a = x[0]\n",
    "    b = x[1]\n",
    "    return ((1.0 - a)**2) + (100.0 * (b - (a**2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hooke_best_nearby(f, delta, point, prevbest, bounds=None, args=[]):\n",
    "    '''\n",
    "        ## given a point, look for a better one nearby\n",
    "        one coord at a time\n",
    "        \n",
    "        f is a function that takes a list of floats (of the same length as point) as an input\n",
    "        args is a dict of any additional arguments to pass to f\n",
    "        delta, and point are same-length lists of floats\n",
    "        prevbest is a float\n",
    "        \n",
    "        point and delta are both modified by the function\n",
    "    '''\n",
    "    z = [x for x in point]\n",
    "    minf = prevbest\n",
    "    ftmp = 0.0\n",
    "    \n",
    "    fev = 0\n",
    "    \n",
    "    for i in range(len(point)):\n",
    "        #see if moving point in the positive delta direction decreases the \n",
    "        z[i] = _value_in_bounds(point[i] + delta[i], bounds[i][0], bounds[i][1])\n",
    "        \n",
    "        ftmp = f(z, *args)\n",
    "        fev += 1\n",
    "        if ftmp < minf:\n",
    "            minf = ftmp\n",
    "        else:\n",
    "            #if not, try moving it in the other direction\n",
    "            delta[i] = -delta[i]\n",
    "            z[i] = _value_in_bounds(point[i] + delta[i], bounds[i][0], bounds[i][1])\n",
    "            \n",
    "            ftmp = f(z, *args)\n",
    "            fev += 1\n",
    "            if ftmp < minf:\n",
    "                minf = ftmp\n",
    "            else:\n",
    "#if moving the point in both delta directions result in no improvement, then just keep the point where it is\n",
    "                z[i] = point[i]\n",
    "\n",
    "    for i in range(len(z)):\n",
    "        point[i] = z[i]\n",
    "    return (minf, fev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _point_in_bounds(point, bounds):\n",
    "    '''\n",
    "        shifts the point so it is within the given bounds\n",
    "    '''\n",
    "    for i in range(len(point)):\n",
    "        if point[i] < bounds[i][0]:\n",
    "            point[i] = bounds[i][0]\n",
    "        elif point[i] > bounds[i][1]:\n",
    "            point[i] = bounds[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_point_in_bounds(point, bounds):\n",
    "    '''\n",
    "        true if the point is in the bounds, else false\n",
    "    '''\n",
    "    out = True\n",
    "    for i in range(len(point)):\n",
    "        if point[i] < bounds[i][0]:\n",
    "            out = False\n",
    "        elif point[i] > bounds[i][1]:\n",
    "            out = False\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value_in_bounds(val, low, high):\n",
    "    if val < low:\n",
    "        return low\n",
    "    elif val > high:\n",
    "        return hight\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hooke(f, startpt, bounds=None, rho=0.5, epsilon=1E-6, itermax=5000, args=[]):\n",
    "#\n",
    "    '''\n",
    "    In this version of the Hooke and Jeeves algorithm, we coerce the function into staying within the given bounds.\n",
    "    basically, any time the function tries to pick a point outside the bounds we shift the point to the boundary\n",
    "    on whatever dimension it is out of bounds in. Implementing bounds this way may be questionable from a theory standpoint,\n",
    "    but that's how COPASI does it, that's how I'll do it too.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = dict()\n",
    "    result['success'] = True\n",
    "    result['message'] = 'success'\n",
    "    \n",
    "    delta = [0.0] * len(startpt)\n",
    "    endpt = [0.0] * len(startpt)\n",
    "    if bounds is None:\n",
    "        # if bounds is none, make it none for all (it will be converted to below)\n",
    "        bounds = [[None,None] for x in startpt]\n",
    "    else:\n",
    "        bounds = [[x[0],x[1]] for x in bounds] #make it so it wont update the original\n",
    "    startpt = [x for x in startpt] #make it so it wont update the original\n",
    "    \n",
    "    fmin = None\n",
    "    nfev = 0\n",
    "    iters = 0\n",
    "    \n",
    "    for bound in bounds:\n",
    "        if bound[0] is None:\n",
    "            bound[0] = float('-inf')\n",
    "        else:\n",
    "            bound[0] = float(bound[0])\n",
    "        if bound[1] is None:\n",
    "            bound[1] = float('inf')\n",
    "        else:\n",
    "            bound[1] = float(bound[1])\n",
    "    try:\n",
    "        # shift \n",
    "        _point_in_bounds(startpt, bounds) #shift startpt so it is within the bounds\n",
    "        \n",
    "        xbefore = [x for x in startpt]\n",
    "        newx = [x for x in startpt]\n",
    "        for i in range(len(startpt)):\n",
    "            delta[i] = abs(startpt[i] * rho)\n",
    "            if (delta[i] == 0.0):\n",
    "                # we always want a non-zero delta because otherwise we'd just be checking the same point over and over\n",
    "                # and wouldn't find a minimum\n",
    "                delta[i] = rho\n",
    "\n",
    "        steplength = rho\n",
    "\n",
    "        fbefore = f(newx, *args)\n",
    "        nfev += 1\n",
    "        \n",
    "        newf = fbefore\n",
    "        fmin = newf\n",
    "        while ((iters < itermax) and (steplength > epsilon)):\n",
    "            iters += 1\n",
    "            #print \"after %5d , f(x) = %.4le at\" % (funevals, fbefore)\n",
    "            \n",
    "#        for j in range(len(startpt)):\n",
    "#            print \"   x[%2d] = %4le\" % (j, xbefore[j])\n",
    "#            pass\n",
    "            \n",
    "###/* find best new point, one coord at a time */\n",
    "            newx = [x for x in xbefore]\n",
    "            (newf, evals) = _hooke_best_nearby(f, delta, newx, fbefore, bounds, args)\n",
    "            \n",
    "            nfev += evals\n",
    "###/* if we made some improvements, pursue that direction */\n",
    "            keep = 1\n",
    "            while ((newf < fbefore) and (keep == 1)):\n",
    "                fmin = newf\n",
    "                for i in range(len(startpt)):\n",
    "###/* firstly, arrange the sign of delta[] */\n",
    "                    if newx[i] <= xbefore[i]:\n",
    "                        delta[i] = -abs(delta[i])\n",
    "                    else:\n",
    "                        delta[i] = abs(delta[i])\n",
    "## #/* now, move further in this direction */\n",
    "                    tmp = xbefore[i]\n",
    "                    xbefore[i] = newx[i]\n",
    "                    newx[i] = _value_in_bounds(newx[i] + newx[i] - tmp, bounds[i][0], bounds[i][1])\n",
    "                fbefore = newf\n",
    "                (newf, evals) = _hooke_best_nearby(f, delta, newx, fbefore, bounds, args)\n",
    "                nfev += evals\n",
    "###/* if the further (optimistic) move was bad.... */\n",
    "                if (newf >= fbefore):\n",
    "                    break\n",
    "                \n",
    "## #/* make sure that the differences between the new */\n",
    "## #/* and the old points are due to actual */\n",
    "## #/* displacements; beware of roundoff errors that */\n",
    "## #/* might cause newf < fbefore */\n",
    "                keep = 0\n",
    "                for i in range(len(startpt)):\n",
    "                    keep = 1\n",
    "                    if ( abs(newx[i] - xbefore[i]) > (0.5 * abs(delta[i])) ):\n",
    "                        break\n",
    "                    else:\n",
    "                        keep = 0\n",
    "            if ((steplength >= epsilon) and (newf >= fbefore)):\n",
    "                steplength = steplength * rho\n",
    "                delta = [x * rho for x in delta]\n",
    "        for x in range(len(xbefore)):\n",
    "            endpt[x] = xbefore[x]\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        result['success'] = False\n",
    "        result['message'] = str(e) + \". line number: \" + str(exc_tb.tb_lineno)\n",
    "    finally:\n",
    "        result['nit'] = iters\n",
    "        result['fevals'] = nfev\n",
    "        result['fun'] = fmin\n",
    "        result['x'] = endpt\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'message': 'success', 'nit': 19, 'fevals': 363, 'fun': 3.637978808415202e-12, 'x': [1.0000019073486328, 1.0000038146972656]}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start = [-1.2,1.0]\n",
    "    res = hooke(rosenbrock, start, bounds=((0,3),(0,10)), rho=0.5)\n",
    "    #res = hooke(rosenbrock, start, rho=0.5)\n",
    "    print(res)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}