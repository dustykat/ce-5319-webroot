{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa29c0-45b7-43bb-9dc7-87af4cd17292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special  # Sigmoid activation function\n",
    "import requests\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Dataset Retrieval Function\n",
    "# ----------------------------\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Download a file from a URL if it does not exist locally.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"File already exists: {filename}\")\n",
    "\n",
    "# URLs for MNIST dataset\n",
    "mnist_train_url = \"http://54.243.252.9/engr-1330-psuedo-course/CECE-1330-PsuedoCourse/6-Projects/P-ImageClassification/mnist_train.csv\"\n",
    "mnist_test_url = \"http://54.243.252.9/engr-1330-psuedo-course/CECE-1330-PsuedoCourse/6-Projects/P-ImageClassification/mnist_test.csv\"\n",
    "\n",
    "# Download datasets\n",
    "download_file(mnist_train_url, \"mnist_train.csv\")\n",
    "download_file(mnist_test_url, \"mnist_test.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Neural Network Class\n",
    "# ----------------------------\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate, verbose=True):\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        self.lr = learning_rate\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Initialize weight matrices with values between -0.5 and 0.5\n",
    "        self.wih = (np.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        self.who = (np.random.rand(self.onodes, self.hnodes) - 0.5)\n",
    "        \n",
    "        # Activation function: Sigmoid\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \"\"\"Train the neural network using backpropagation.\"\"\"\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), hidden_outputs.T)\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), inputs.T)\n",
    "        \n",
    "    def query(self, inputs_list):\n",
    "        \"\"\"Query the network for predictions.\"\"\"\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Helper Functions\n",
    "# ----------------------------\n",
    "def load_data(filename):\n",
    "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "def normalize_inputs(all_values):\n",
    "    \"\"\"Normalize input values from 0-255 to a range of 0.01 to 1.00.\"\"\"\n",
    "    return (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "def train_network(model, data, epochs=1, manual_lr_decay=True):\n",
    "    \"\"\"Train the neural network over multiple epochs.\"\"\"\n",
    "    for _ in range(epochs):\n",
    "        for record in data:\n",
    "            all_values = record.split(',')\n",
    "            inputs = normalize_inputs(all_values)\n",
    "            targets = np.zeros(model.onodes) + 0.01\n",
    "            targets[int(all_values[0])] = 0.99\n",
    "            model.train(inputs, targets)\n",
    "        if manual_lr_decay:\n",
    "            model.lr *= 0.9  # Manual learning rate scaling\n",
    "    if model.verbose:\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "def evaluate_network(model, data):\n",
    "    \"\"\"Evaluate the model on test data.\"\"\"\n",
    "    scorecard = []\n",
    "    for record in data:\n",
    "        all_values = record.split(',')\n",
    "        correct_label = int(all_values[0])\n",
    "        inputs = normalize_inputs(all_values)\n",
    "        outputs = model.query(inputs)\n",
    "        label = np.argmax(outputs)\n",
    "        scorecard.append(1 if label == correct_label else 0)\n",
    "    accuracy = sum(scorecard) / len(scorecard)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Model Initialization & Training\n",
    "# ----------------------------\n",
    "input_nodes = 784  # 28x28 pixels\n",
    "hidden_nodes = 110  # Intermediate hidden layer size\n",
    "output_nodes = 10  # 10 classification labels\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Create neural network instance\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, verbose=True)\n",
    "\n",
    "# Load training and test data\n",
    "training_data = load_data(\"mnist_train.csv\")\n",
    "test_data = load_data(\"mnist_test.csv\")\n",
    "\n",
    "# Train the network\n",
    "train_network(n, training_data, epochs=1)\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate_network(n, test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Common Environment",
   "language": "python",
   "name": "python-my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
