{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "'''\n",
    "     This is a direct python port of Mark G. Johnson's C implementation of the Hooke and Jeeves algorithm\n",
    "     \n",
    "     Sean R. Johnson, July 7, 2013\n",
    "     \n",
    "     immediately below is the original documentation\n",
    "     in the body, comments marked with ## are from the original,\n",
    "     other comments are my own\n",
    "'''\n",
    "\n",
    "#/* Nonlinear Optimization using the algorithm of Hooke and Jeeves  */\n",
    "#/*\t12 February 1994\tauthor: Mark G. Johnson \t   */\n",
    "\n",
    "#/* Find a point X where the nonlinear function f(X) has a local    */\n",
    "#/* minimum.  X is an n-vector and f(X) is a scalar.  In mathe-\t   */\n",
    "#/* matical notation  f: R^n -> R^1.  The objective function f()    */\n",
    "#/* is not required to be continuous.  Nor does f() need to be\t   */\n",
    "#/* differentiable.  The program does not use or require \t   */\n",
    "#/* derivatives of f().\t\t\t\t\t\t   */\n",
    "\n",
    "#/* The software user supplies three things: a subroutine that\t   */\n",
    "#/* computes f(X), an initial \"starting guess\" of the minimum point */\n",
    "#/* X, and values for the algorithm convergence parameters.  Then   */\n",
    "#/* the program searches for a local minimum, beginning from the    */\n",
    "#/* starting guess, using the Direct Search algorithm of Hooke and  */\n",
    "#/* Jeeves.\t\t\t\t\t\t\t   */\n",
    "\n",
    "#/* This C program is adapted from the Algol pseudocode found in    */\n",
    "#/* \"Algorithm 178: Direct Search\" by Arthur F. Kaupe Jr., Commun-  */\n",
    "#/* ications of the ACM, Vol 6. p.313 (June 1963).  It includes the */\n",
    "#/* improvements suggested by Bell and Pike (CACM v.9, p. 684, Sept */\n",
    "#/* 1966) and those of Tomlin and Smith, \"Remark on Algorithm 178\"  */\n",
    "#/* (CACM v.12).  The original paper, which I don't recommend as    */\n",
    "#/* highly as the one by A. Kaupe, is:  R. Hooke and T. A. Jeeves,  */\n",
    "#/* \"Direct Search Solution of Numerical and Statistical Problems\", */\n",
    "#/* Journal of the ACM, Vol. 8, April 1961, pp. 212-229. \t   */\n",
    "\n",
    "#/* Calling sequence:\t\t\t\t\t\t   */\n",
    "#/*  int hooke(nvars, startpt, endpt, rho, epsilon, itermax)\t   */\n",
    "#/*\t\t\t\t\t\t\t\t   */\n",
    "#/*     nvars\t   {an integer}  This is the number of dimensions  */\n",
    "#/*\t\t   in the domain of f().  It is the number of\t   */\n",
    "#/*\t\t   coordinates of the starting point (and the\t   */\n",
    "#/*\t\t   minimum point.)\t\t\t\t   */\n",
    "#/*     startpt\t   {an array of doubles}  This is the user-\t   */\n",
    "#/*\t\t   supplied guess at the minimum.\t\t   */\n",
    "#/*     endpt\t   {an array of doubles}  This is the location of  */\n",
    "#/*\t\t   the local minimum, calculated by the program    */\n",
    "#/*     rho\t   {a double}  This is a user-supplied convergence */\n",
    "#/*\t\t   parameter (more detail below), which should be  */\n",
    "#/*\t\t   set to a value between 0.0 and 1.0.\tLarger\t   */\n",
    "#/*\t\t   values of rho give greater probability of\t   */\n",
    "#/*\t\t   convergence on highly nonlinear functions, at a */\n",
    "#/*\t\t   cost of more function evaluations.  Smaller\t   */\n",
    "#/*\t\t   values of rho reduces the number of evaluations */\n",
    "#/*\t\t   (and the program running time), but increases   */\n",
    "#/*\t\t   the risk of nonconvergence.\tSee below.\t   */\n",
    "#/*     epsilon\t   {a double}  This is the criterion for halting   */\n",
    "#/*\t\t   the search for a minimum.  When the algorithm   */\n",
    "#/*\t\t   begins to make less and less progress on each   */\n",
    "#/*\t\t   iteration, it checks the halting criterion: if  */\n",
    "#/*\t\t   the stepsize is below epsilon, terminate the    */\n",
    "#/*\t\t   iteration and return the current best estimate  */\n",
    "#/*\t\t   of the minimum.  Larger values of epsilon (such */\n",
    "#/*\t\t   as 1.0e-4) give quicker running time, but a\t   */\n",
    "#/*\t\t   less accurate estimate of the minimum.  Smaller */\n",
    "#/*\t\t   values of epsilon (such as 1.0e-7) give longer  */\n",
    "#/*\t\t   running time, but a more accurate estimate of   */\n",
    "#/*\t\t   the minimum. \t\t\t\t   */\n",
    "#/*     itermax\t   {an integer}  A second, rarely used, halting    */\n",
    "#/*\t\t   criterion.  If the algorithm uses >= itermax    */\n",
    "#/*\t\t   iterations, halt.\t\t\t\t   */\n",
    "\n",
    "\n",
    "#/* The user-supplied objective function f(x,n) should return a C   */\n",
    "#/* \"double\".  Its  arguments are  x -- an array of doubles, and    */\n",
    "#/* n -- an integer.  x is the point at which f(x) should be\t   */\n",
    "#/* evaluated, and n is the number of coordinates of x.\tThat is,   */\n",
    "#/* n is the number of coefficients being fitted.\t\t   */\n",
    "\n",
    "#/* rho, the algorithm convergence control\t\t\t   */\n",
    "#/*\tThe algorithm works by taking \"steps\" from one estimate of */\n",
    "#/*    a minimum, to another (hopefully better) estimate.  Taking   */\n",
    "#/*    big steps gets to the minimum more quickly, at the risk of   */\n",
    "#/*    \"stepping right over\" an excellent point.  The stepsize is   */\n",
    "#/*    controlled by a user supplied parameter called rho.  At each */\n",
    "#/*    iteration, the stepsize is multiplied by rho  (0 < rho < 1), */\n",
    "#/*    so the stepsize is successively reduced.\t\t\t   */\n",
    "#/*\tSmall values of rho correspond to big stepsize changes,    */\n",
    "#/*    which make the algorithm run more quickly.  However, there   */\n",
    "#/*    is a chance (especially with highly nonlinear functions)\t   */\n",
    "#/*    that these big changes will accidentally overlook a\t   */\n",
    "#/*    promising search vector, leading to nonconvergence.\t   */\n",
    "#/*\tLarge values of rho correspond to small stepsize changes,  */\n",
    "#/*    which force the algorithm to carefully examine nearby points */\n",
    "#/*    instead of optimistically forging ahead.\tThis improves the  */\n",
    "#/*    probability of convergence.\t\t\t\t   */\n",
    "#/*\tThe stepsize is reduced until it is equal to (or smaller   */\n",
    "#/*    than) epsilon.  So the number of iterations performed by\t   */\n",
    "#/*    Hooke-Jeeves is determined by rho and epsilon:\t\t   */\n",
    "#/*\t    rho**(number_of_iterations) = epsilon\t\t   */\n",
    "#/*\tIn general it is a good idea to set rho to an aggressively */\n",
    "#/*    small value like 0.5 (hoping for fast convergence).  Then,   */\n",
    "#/*    if the user suspects that the reported minimum is incorrect  */\n",
    "#/*    (or perhaps not accurate enough), the program can be run\t   */\n",
    "#/*    again with a larger value of rho such as 0.85, using the\t   */\n",
    "#/*    result of the first minimization as the starting guess to    */\n",
    "#/*    begin the second minimization.\t\t\t\t   */\n",
    "\n",
    "#/* Normal use: (1) Code your function f() in the C language\t   */\n",
    "#/*\t       (2) Install your starting guess {or read it in}\t   */\n",
    "#/*\t       (3) Run the program\t\t\t\t   */\n",
    "#/*\t       (4) {for the skeptical}: Use the computed minimum   */\n",
    "#/*\t\t      as the starting point for another run\t   */\n",
    "\n",
    "#/* Data Fitting:\t\t\t\t\t\t   */\n",
    "#/*\tCode your function f() to be the sum of the squares of the */\n",
    "#/*\terrors (differences) between the computed values and the   */\n",
    "#/*\tmeasured values.  Then minimize f() using Hooke-Jeeves.    */\n",
    "#/*\tEXAMPLE: you have 20 datapoints (ti, yi) and you want to   */\n",
    "#/*\tfind A,B,C such that  (A*t*t) + (B*exp(t)) + (C*tan(t))    */\n",
    "#/*\tfits the data as closely as possible.  Then f() is just    */\n",
    "#/*\tf(x) = SUM (measured_y[i] - ((A*t[i]*t[i]) + (B*exp(t[i])) */\n",
    "#/*\t\t\t\t  + (C*tan(t[i]))))^2\t\t   */\n",
    "#/*\twhere x[] is a 3-vector consisting of {A, B, C}.\t   */\n",
    "\n",
    "#/*\t\t\t\t\t\t\t\t   */\n",
    "#/*  The author of this software is M.G. Johnson.\t\t   */\n",
    "#/*  Permission to use, copy, modify, and distribute this software  */\n",
    "#/*  for any purpose without fee is hereby granted, provided that   */\n",
    "#/*  this entire notice is included in all copies of any software   */\n",
    "#/*  which is or includes a copy or modification of this software   */\n",
    "#/*  and in all copies of the supporting documentation for such\t   */\n",
    "#/*  software.  THIS SOFTWARE IS BEING PROVIDED \"AS IS\", WITHOUT    */\n",
    "#/*  ANY EXPRESS OR IMPLIED WARRANTY.  IN PARTICULAR, NEITHER THE   */\n",
    "#/*  AUTHOR NOR AT&T MAKE ANY REPRESENTATION OR WARRANTY OF ANY\t   */\n",
    "#/*  KIND CONCERNING THE MERCHANTABILITY OF THIS SOFTWARE OR ITS    */\n",
    "#/*  FITNESS FOR ANY PARTICULAR PURPOSE. \t\t\t   */\n",
    "#/*\t\t\t\t\t\t\t\t   */\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    '''\n",
    "        ## Rosenbrocks classic parabolic valley (\"banana\") function\n",
    "    '''\n",
    "    a = x[0]\n",
    "    b = x[1]\n",
    "    return ((1.0 - a)**2) + (100.0 * (b - (a**2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "153def _hooke_best_nearby(f, delta, point, prevbest, bounds=None, args=[]):\n",
    "154    '''\n",
    "155        ## given a point, look for a better one nearby\n",
    "156        one coord at a time\n",
    "157        \n",
    "158        f is a function that takes a list of floats (of the same length as point) as an input\n",
    "159        args is a dict of any additional arguments to pass to f\n",
    "160        delta, and point are same-length lists of floats\n",
    "161        prevbest is a float\n",
    "162        \n",
    "163        point and delta are both modified by the function\n",
    "164    '''\n",
    "165    z = [x for x in point]\n",
    "166    minf = prevbest\n",
    "167    ftmp = 0.0\n",
    "168    \n",
    "169    fev = 0\n",
    "170    \n",
    "171    for i in range(len(point)):\n",
    "172        #see if moving point in the positive delta direction decreases the \n",
    "173        z[i] = _value_in_bounds(point[i] + delta[i], bounds[i][0], bounds[i][1])\n",
    "174        \n",
    "175        ftmp = f(z, *args)\n",
    "176        fev += 1\n",
    "177        if ftmp < minf:\n",
    "178            minf = ftmp\n",
    "179        else:\n",
    "180            #if not, try moving it in the other direction\n",
    "181            delta[i] = -delta[i]\n",
    "182            z[i] = _value_in_bounds(point[i] + delta[i], bounds[i][0], bounds[i][1])\n",
    "183            \n",
    "184            ftmp = f(z, *args)\n",
    "185            fev += 1\n",
    "186            if ftmp < minf:\n",
    "187                minf = ftmp\n",
    "188            else:\n",
    "#if moving the point in both delta directions result in no improvement, then just keep the point where it is\n",
    "190                z[i] = point[i]\n",
    "191\n",
    "192    for i in range(len(z)):\n",
    "193        point[i] = z[i]\n",
    "194    return (minf, fev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "195                \n",
    "196def _point_in_bounds(point, bounds):\n",
    "197    '''\n",
    "198        shifts the point so it is within the given bounds\n",
    "199    '''\n",
    "200    for i in range(len(point)):\n",
    "201        if point[i] < bounds[i][0]:\n",
    "202            point[i] = bounds[i][0]\n",
    "203        elif point[i] > bounds[i][1]:\n",
    "204            point[i] = bounds[i][1]\n",
    "205def _is_point_in_bounds(point, bounds):\n",
    "206    '''\n",
    "207        true if the point is in the bounds, else false\n",
    "208    '''\n",
    "209    out = True\n",
    "210    for i in range(len(point)):\n",
    "211        if point[i] < bounds[i][0]:\n",
    "212            out = False\n",
    "213        elif point[i] > bounds[i][1]:\n",
    "214            out = False\n",
    "215    return out\n",
    "216\n",
    "217def _value_in_bounds(val, low, high):\n",
    "218    if val < low:\n",
    "219        return low\n",
    "220    elif val > high:\n",
    "221        return hight\n",
    "222    else:\n",
    "223        return val\n",
    "224            \n",
    "def hooke(f, startpt, bounds=None, rho=0.5, epsilon=1E-6, itermax=5000, args=[]):\n",
    "'''\n",
    "In this version of the Hooke and Jeeves algorithm, we coerce the function into staying within the given bounds.\n",
    "basically, any time the function tries to pick a point outside the bounds we shift the point to the boundary\n",
    "on whatever dimension it is out of bounds in. Implementing bounds this way may be questionable from a theory standpoint,\n",
    "but that's how COPASI does it, that's how I'll do it too.\n",
    "'''\n",
    "233    \n",
    "234    result = dict()\n",
    "235    result['success'] = True\n",
    "236    result['message'] = 'success'\n",
    "237    \n",
    "238    delta = [0.0] * len(startpt)\n",
    "239    endpt = [0.0] * len(startpt)\n",
    "240    if bounds is None:\n",
    "241        # if bounds is none, make it none for all (it will be converted to below)\n",
    "242        bounds = [[None,None] for x in startpt]\n",
    "243    else:\n",
    "244        bounds = [[x[0],x[1]] for x in bounds] #make it so it wont update the original\n",
    "245    startpt = [x for x in startpt] #make it so it wont update the original\n",
    "246    \n",
    "247    fmin = None\n",
    "248    nfev = 0\n",
    "249    iters = 0\n",
    "250    \n",
    "251    for bound in bounds:\n",
    "252        if bound[0] is None:\n",
    "253            bound[0] = float('-inf')\n",
    "254        else:\n",
    "255            bound[0] = float(bound[0])\n",
    "256        if bound[1] is None:\n",
    "257            bound[1] = float('inf')\n",
    "258        else:\n",
    "259            bound[1] = float(bound[1])\n",
    "260    try:\n",
    "261        # shift \n",
    "262        _point_in_bounds(startpt, bounds) #shift startpt so it is within the bounds\n",
    "263        \n",
    "264        xbefore = [x for x in startpt]\n",
    "265        newx = [x for x in startpt]\n",
    "266        for i in range(len(startpt)):\n",
    "267            delta[i] = abs(startpt[i] * rho)\n",
    "268            if (delta[i] == 0.0):\n",
    "269                # we always want a non-zero delta because otherwise we'd just be checking the same point over and over\n",
    "270                # and wouldn't find a minimum\n",
    "271                delta[i] = rho\n",
    "272\n",
    "273        steplength = rho\n",
    "274\n",
    "275        fbefore = f(newx, *args)\n",
    "276        nfev += 1\n",
    "277        \n",
    "278        newf = fbefore\n",
    "279        fmin = newf\n",
    "280        while ((iters < itermax) and (steplength > epsilon)):\n",
    "281            iters += 1\n",
    "282            #print \"after %5d , f(x) = %.4le at\" % (funevals, fbefore)\n",
    "283            \n",
    "#        for j in range(len(startpt)):\n",
    "#            print \"   x[%2d] = %4le\" % (j, xbefore[j])\n",
    "#            pass\n",
    "287            \n",
    "###/* find best new point, one coord at a time */\n",
    "289            newx = [x for x in xbefore]\n",
    "290            (newf, evals) = _hooke_best_nearby(f, delta, newx, fbefore, bounds, args)\n",
    "291            \n",
    "292            nfev += evals\n",
    "###/* if we made some improvements, pursue that direction */\n",
    "294            keep = 1\n",
    "295            while ((newf < fbefore) and (keep == 1)):\n",
    "296                fmin = newf\n",
    "297                for i in range(len(startpt)):\n",
    "###/* firstly, arrange the sign of delta[] */\n",
    "299                    if newx[i] <= xbefore[i]:\n",
    "300                        delta[i] = -abs(delta[i])\n",
    "301                    else:\n",
    "302                        delta[i] = abs(delta[i])\n",
    "## #/* now, move further in this direction */\n",
    "304                    tmp = xbefore[i]\n",
    "305                    xbefore[i] = newx[i]\n",
    "306                    newx[i] = _value_in_bounds(newx[i] + newx[i] - tmp, bounds[i][0], bounds[i][1])\n",
    "307                fbefore = newf\n",
    "308                (newf, evals) = _hooke_best_nearby(f, delta, newx, fbefore, bounds, args)\n",
    "309                nfev += evals\n",
    "###/* if the further (optimistic) move was bad.... */\n",
    "311                if (newf >= fbefore):\n",
    "312                    break\n",
    "313                \n",
    "## #/* make sure that the differences between the new */\n",
    "## #/* and the old points are due to actual */\n",
    "## #/* displacements; beware of roundoff errors that */\n",
    "## #/* might cause newf < fbefore */\n",
    "318                keep = 0\n",
    "319                for i in range(len(startpt)):\n",
    "320                    keep = 1\n",
    "321                    if ( abs(newx[i] - xbefore[i]) > (0.5 * abs(delta[i])) ):\n",
    "322                        break\n",
    "323                    else:\n",
    "324                        keep = 0\n",
    "325            if ((steplength >= epsilon) and (newf >= fbefore)):\n",
    "326                steplength = steplength * rho\n",
    "327                delta = [x * rho for x in delta]\n",
    "328        for x in range(len(xbefore)):\n",
    "329            endpt[x] = xbefore[x]\n",
    "330    except Exception as e:\n",
    "331        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "332        result['success'] = False\n",
    "333        result['message'] = str(e) + \". line number: \" + str(exc_tb.tb_lineno)\n",
    "334    finally:\n",
    "335        result['nit'] = iters\n",
    "336        result['fevals'] = nfev\n",
    "337        result['fun'] = fmin\n",
    "338        result['x'] = endpt\n",
    "339    \n",
    "340    return result\n",
    "341    \n",
    "342def main():\n",
    "343    start = [-1.2,1.0]\n",
    "344    res = hooke(rosenbrock, start, bounds=((0,3),(0,10)), rho=0.5)\n",
    "345    #res = hooke(rosenbrock, start, rho=0.5)\n",
    "346    print res\n",
    "347if __name__ == \"__main__\":\n",
    "348    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n     This is a direct python port of Mark G. Johnson's C implementation of the Hooke and Jeeves algorithm\\n     \\n     Sean R. Johnson, July 7, 2013\\n     \\n     immediately below is the original documentation\\n     in the body, comments marked with ## are from the original,\\n     other comments are my own\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
